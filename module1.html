<!doctype html>
<html lang="en">
<head>
	<base target='_blank'/> <!--will make each link default open in new tab-->
    <meta charset="utf-8"/>
	<meta name="google-site-verification" content="Hl1D8Wi_Na9rBhnPm51m6rstMdR3t3WR38vQS9t1keo" /><!--verifying site for the purpose of google-->
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=0, shrink-to-fit=no"/><!--viewport is user's visible area of web page-->
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>    
    <meta name="description" content="An online course/workshop for learning how to program online social science experiments."/><!--To increase SEO, add description, keywords, author, etc. -->
    <meta name="keywords" content="Social Science, JavaScript, HTML, CSS, Qualtrics, Amazon Mechanical Turk"/>
    <meta name="author" content="Christina Bejjani"/>

	<title>Module 1 of Introductory Programming for Online Social Science Experiments</title>
	
	<!-- Favicons-->
	<link href="files/favi_icon_website.png" rel="icon" type="image/x-icon" /> 
	<link rel="apple-touch-icon" href="files/favi_icon_website_180.png" sizes="180x180">
	<link rel="icon" href="files/favi_icon_website_32.png" sizes="32x32" type="image/png">
	<link rel="icon" href="files/favi_icon_website_16.png" sizes="16x16" type="image/png">
	
	<!--This is for the open graph framework, which sites like Facebook, Twitter, LinkedIn etc. use, esp when the site URL is shared -->
	<meta property='og:url' content='https://socsciprogramming.github.io/module1.html'/>
	<meta property='og:title' content='Introductory Programming for Online Social Science Experiments'/>
	<meta property='og:description' content='An online course/workshop for learning how to program online social science experiments.'/>
	<meta property='og:type' content='website'/>
	<meta property='og:image' content='files/twittercard.png'/>
	<meta property="og:image:type" content="image/png">
	<meta property="og:image:width" content="1280">
	<meta property="og:image:height" content="640">
		
	<!--This is for those little thumbnails when the link is shared on twitter -->
	<meta name='twitter:card' content='summary'/>
	<meta name='twitter:site' content='@chbejjani'/>
	<meta name='twitter:creator' content='@chbejjani'/>
	<meta name='twitter:url' content='https://socsciprogramming.github.io/module1.html'/>
	<meta name='twitter:image' content='files/twittercard.png'/>
	<meta name='twitter:description' content='An online course/workshop for learning how to program online social science experiments.'/>
	<meta name='twitter:title' content='Introductory Programming for Online Social Science Experiments'/>
	
    <!--rel canonical is a way of defining canonical page for similar or duplicate pages -->
	<link href='https://socsciprogramming.github.io/module1.html' rel='canonical'/> 
	
    <!-- Bootstrap core CSS + font awesome JS for icons-->
    <link href="css/bootstrap.min.css" rel="stylesheet">
	<script src="https://kit.fontawesome.com/25e7f7a6fa.js" crossorigin="anonymous"></script>
	
	<!-- Custom CSS -->
	<link href="css/allpages.css" rel="stylesheet">
	
	<!-- Loading fonts; pairing serif fonts in headers w/ sans serif for body-->
	<link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&family=Playfair+Display+SC:wght@400;700&family=Playfair+Display:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
	
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-5K6E5T95PP"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-5K6E5T95PP');
	</script>
</head>
<body>
	<nav class="navbar navbar-expand-md fixed-top bg-blue">
		<button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
			<span class="fas fa-bars"></span>
		</button>
		<a class="navbar-brand" href="#" target="_self">
			<img src="files/logo.png" width="30" height="30" class="d-inline-block align-top" alt="logo">
		</a>
		<div class="collapse navbar-collapse" id="navbarNavDropdown">
			<ul class="navbar-nav">
				<li class="nav-item">
					<a class="nav-link navb-link" href="index.html" target="_self">Home <span class="sr-only">(current)</span></a>
				</li>
				<li class="nav-item">
					<a class="nav-link navb-link" href="about.html" target="_self">About</a>
				</li>
				<li class="nav-item">
					<a class="nav-link navb-link" href="contribute.html" target="_self">How to Contribute</a>
				</li>
				<li class="nav-item">
					<a class="nav-link navb-link" href="wishlist.html" target="_self">Wishlist</a>
				</li>
				<li class="nav-item dropdown d-sm-block d-md-none">
					<a class="nav-link dropdown-toggle navb-link" href="#" id="smallerscreenmenu" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Modules</a>
					<div class="dropdown-menu bg-blue" aria-labelledby="smallerscreenmenu">
						<a class="dropdown-item navb-link" href="module1.html" target="_self">Module 1</a>
						<a class="dropdown-item navb-link" href="module2.html" target="_self">Module 2</a>
						<a class="dropdown-item navb-link" href="module3.html" target="_self">Module 3</a>
						<a class="dropdown-item navb-link" href="module4.html" target="_self">Module 4</a>
					</div>
				</li>
			</ul>
		</div>
	</nav>
	<div class="row" id="body-row">
		<div id="sidebar-container" class="d-none d-md-block col-2 bg-grey">
			<ul class="list-group sticky-top sticky-offset">
				<li class="list-group-item text-muted d-flex align-items-center">
					<small>MODULES</small>
				</li>
				<a href="#submenu1" target="_self" data-toggle="collapse" aria-expanded="true" class="list-group-item flex-column align-items-start">
					<div class="d-flex w-100 justify-content-start align-items-center">
						<span class="if-collapsed fas fa-angle-up mr-3"></span>
						<span class="if-not-collapsed fas fa-angle-down mr-3"></span>
						<span class="copy-link active">1: Crowdsourced Experiments</span>
					</div>
				</a>
				<div id="submenu1" class="sidebar-submenu">
					<a href="#subsec11" target="_self" class="list-group-item">
						<span class="copy-link anchor">What are crowdsourced experiments?</span>
					</a>
					<a href="#subsec12" target="_self" class="list-group-item">
						<span class="copy-link anchor">Designing online studies</span>
					</a>
					<a href="#subsec13" target="_self" class="list-group-item">
						<span class="copy-link anchor">Additional Considerations</span>
					</a>
				</div>
				<a href="module2.html" target="_self" aria-expanded="false" class="list-group-item flex-column align-items-start">
					<div class="d-flex w-100 justify-content-start align-items-center">
						<span class="if-collapsed fas fa-angle-up mr-3"></span>
						<!--<span class="if-not-collapsed fas fa-angle-down mr-3"></span>-->
						<span class=" copy-link">2: Basic Survey Design</span>
					</div>
				</a>
				<a href="module3.html" target="_self" aria-expanded="false" class="list-group-item flex-column align-items-start">
					<div class="d-flex w-100 justify-content-start align-items-center">
						<span class="if-collapsed fas fa-angle-up mr-3"></span>
						<!--<span class="if-not-collapsed fas fa-angle-down mr-3"></span>-->
						<span class="copy-link">3: Customized Design with JavaScript, HTML, &amp; CSS</span>
					</div>
				</a>
				<a href="module4.html" target="_self" aria-expanded="false" class="list-group-item flex-column align-items-start">
					<div class="d-flex w-100 justify-content-start align-items-center">
						<span class="if-collapsed fas fa-angle-up mr-3"></span>
						<!--<span class="if-not-collapsed fas fa-angle-down mr-3"></span>-->
						<span class="copy-link">4: Advanced Customization</span>
					</div>
				</a>
			</ul>
		</div>
		<div class="col py-3" id="page-content">
			<h1>Module 1: Crowdsourced Experiments</h1>

			<hr>
			
			<div class="card">
				<div class="card-header">Learning Goals</div>
				<div class="card-body">
					<ul class="fa-ul card-text">
						<li><i class="fa-li fas fa-user"></i>Identify the lingo and demographics of Amazon Mechanical Turk (MTurk)</li>
						<li><i class="fa-li fas fa-user-clock"></i>Describe the benefits and pitfalls of crowdsourced research</li>
						<li><i class="fa-li fas fa-users"></i>Diagnose what sample MTurk experiments do wrong and what they should do instead</li>
						<li><i class="fa-li fas fa-users-cog"></i>Synthesize common tips for running MTurk participants into your research</li>
					</ul>
				</div>
			</div>

			<p>Welcome!</p>
			
			<hr>
			
			<p>This course is designed for any researchers - whether in academia or industry, or PIs, post-doctoral researchers, graduate students, undergraduate students, or post-bac RAs - who wish to use crowdsourced populations to run their social science experiments online. As part of this objective, we will go over the many ways one could program a survey or experiment, but we will not go over the basics of <b>how</b> to design proper surveys (e.g., social science research methods) or what makes for good experiments. We will also not cover every little detail about JavaScript, HTML, and CSS. This course is more applied and advanced than a standard Introductory level course, but we hope to nonetheless interest you in pursuing more advanced customization of experiments, websites, and more.</p>

			<h2 id="subsec11" class="pad1">What are crowdsourced experiments?</h2>

			<p>Crowdsourcing, according to <a href="https://en.wikipedia.org/wiki/Crowdsourcing" class="copy-link">Wikipedia</a>, is "sourcing model in which individuals or organizations obtain goods and services, including ideas, voting, micro-tasks and finances, from a large, relatively open and often rapidly evolving group of participants." For example, Wikipedia is a crowdsourced encyclopedia online, with participants from all around the world contributing to the body of knowledge (a common good). This repository is meant to be crowdsourced, as a Github page that others can edit in time as more information becomes available. That is, this course is self-paced for all students, but students can also become collaborators over time.</p>
			
			<p>In the realm of research, as <a href="https://pubmed.ncbi.nlm.nih.gov/28803699/" class="copy-link">Stewart, Chandler, and Paolacci (2017)</a> discuss, researchers use online labor markets to match interested participants who can earn money to complete research studies. There are a number of crowdsourced sites: <a href="https://www.prolific.co/" class="copy-link">Prolific</a>, <a href="https://luc.id/" class="copy-link">Lucid</a>, <a href="https://www.clickworker.com/" class="copy-link">Clickworker</a>, <a href="https://www.microworkers.com/" class="copy-link">Microworkers</a>, and <a href="http://www.crowdworker.com/who-are-the-typical-crowdworkers/" class="copy-link">CrowdWorkers</a>. There are likely more than are listed here, although not all will be particularly well known. This particular course focuses on <a href="https://www.mturk.com/" class="copy-link">Amazon Mechcanial Turk</a>, one of the most popular crowdsourcing sites used in the United States (please also see <a href="wishlist.html" class="copy-link">Wishlist</a>).</p>
			
			<img src="files/srclogo.png" class="rounded mx-auto d-block" alt="crowdsourcedlogos"></img>
			
			<h4 id="subsec11t1" class="pad1">What is Amazon Mechanical Turk (MTurk)?</h4>
			
			<div class="alert alert-primary" role="alert">This tutorial is also available in video form on Coursera.</div>
			
			<p><a href="https://pubmed.ncbi.nlm.nih.gov/28803699/" class="copy-link">Stewart, Chandler, and Paolacci (2017)</a> suggest that in 2017, 24% of articles in <i>Cognition</i>, 29% of articles in <i>Cognitive Psychology</i>, 31% of articles in <i>Cognitive Science</i>, and 11% of articles in <i>Journal of Experimental psychology: Learning, Memory, and Cognition</i> mention MTurk or another crowdsourced experiment site, highlighting that there is strong demand for using these platforms to recruit participants. This demand has likely only increased given work-from-home attitudes and the shift to virtual platforms during the COVID-19 pandemic.</p>
			
			<p>Why is MTurk so popular? One major benefit is that crowdsourcing sites tend to yield results much faster than running participants in person. You can take a look at the <a href="http://techlist.com/mturk/global-mturk-worker-map.php" class="copy-link">Geographic distribution of MTurk participants</a>. There is a pretty decent MTurk pool for researchers in the United States, and there are about <a href="https://www.behind-the-enemy-lines.com/2018/01/how-many-mechanical-turk-workers-are.html" class="copy-link">100K-200K unique participants on MTurk</a>, with 2K-5K active on MTurk at any given time and about half of the population changing within 12-18 months.</p> 
			
			<p>In <a href="http://www.behind-the-enemy-lines.com/2015/04/demographics-of-mechanical-turk-now.html" class="copy-link">2015</a>:</p> 
			
			<ul class="fa-ul">
				<li><i class="fa-li fas fa-user"></i>~80% of the MTurk participants were from the United States, and the other 20% mostly from India.</li>
				<li><i class="fa-li fas fa-user-clock"></i>~50% were 30-year-olds, ~20% were 20-year-olds and ~20% were 40-year-olds.</li>
				<li><i class="fa-li fas fa-users"></i>~40% were single, ~40% were married, and ~10% were cohabitating.</li>
				<li><i class="fa-li fas fa-users-cog"></i>The median household income was ~$50K per year for U.S. participants.</li>
			</ul>
			
			<p>In other words, a typical MTurk participant lives in the U.S. or India, is 20-36 years old, earns $25,000-60,000 a year (depending on where they live), and thus matches the profile of a (procrastinating) graduate student or post-doc.</p>
			
			<p>Of course, these demographics have likely changed to some extent. <a href="https://mturk-surveys.appspot.com/#/gender/all" class="copy-link">This app</a> is meant to show you MTurk gender, year of birth, marital status, household size, and household income data on an hourly, daily, or day of week basis (see <a href="https://www.behind-the-enemy-lines.com/2015/06/an-api-for-mturk-demographics.html" class="copy-link">blog post</a>).</p>
			
			<p>Demographically, MTurk participants tend to be more diverse than college student samples, but are not representation of the U.S. population as a whole (Hispanics of all races and African-Americans are under-represented), and are younger, more educated, less religious, more liberal, and more likely to be unemployed or underemployed and have lower incomes than the population as a whole (see <a href="https://pubmed.ncbi.nlm.nih.gov/28803699/" class="copy-link">Stewart, Chandler, and Paolacci (2017)</a> for review). Psychologically, MTurk participants score higher on learning goal orientation, need for cognition, and traits associated with autism spectrum disorders, report more social anxiety and are more introverted than both college students and the population as a whole, are less tolerant of physical and psychological discomfort than college students, and are more neurotic (see <a href="https://pubmed.ncbi.nlm.nih.gov/28803699/" class="copy-link">Stewart, Chandler, and Paolacci (2017)</a> for review).</p>
			
			<p>There are also important differences that come specifically from crowdsourcing. When using MTurk or other crowdsourcing platforms, you are usually posting your study/task into the 'ether'. Your study is available on a first come, first served basis, and that incentivizes certain behaviors. For example, some participants have become good at taking advantage of the platforms to find available studies and especially the ones that pay the best. In other words, participants may vary on their level of savviness and connectedness with other site participants, who may inform friends about a well-paying study. They'll definitely also vary in characteristics like personality, ethnicity, mobile phone use, and level of experience as a function of the time of day when a study is posted. Below in the <a href="#subsec13t5" class="copy-link">Unknown Frontiers</a> section, I discuss the impact of COVID-19; one potential impact is the particular demographics of your study. Moreover, as stated above, MTurk has both a U.S. and India population; at certain times of day, the U.S. population is more likely to be asleep, while the Indian population is more likely to be awake and active, and vice versa (see demographic app targeter above for an example). Arechar, Kraft-Todd, and Rand (2017) have suggested that participants who do studies on the weekend and later in the night are less experienced with online studies. Participants who complete a study early may also differ personality-wise from those who complete this later--although this may not be specific to MTurk or crowdsourcing. I was (informally) told that this is also true of psychology pool participants, who are more conscientious earlier in the semester than later, when we're closer to the deadline for participation.</p>

			<p>You can also imagine ways in which this crowdsourcing behavior might impact design considerations. If participants are searching for tasks to complete, especially ones that are well-paying, they are also likely to prioritize studies that are not long and arduous--and as researchers, we have to take this into account. That means crowdsourcing tasks tend to be shorter. Participants who are doing online studies are also likely to be multitasking (e.g., not being alone, watching TV, etc.). That may differ from in person studies in a lab, but that may also depend on the extent to which a lab enforces a 'no-phone' rule etc. That doesn't mean behavior isn't similar (more on that in a bit). But it does mean that your instructions have to be REALLY clear. In person participants can ask you questions if they don't understand what they're supposed to do; online participants cannot.</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
						
			<h4 id="subsec11t2" class="pad1">How to use Amazon Mechanical Turk</h4>
			
			<!--Walk students through the MTurk site and its different components, including MTurk sandbox-->
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
			
			<h4 id="subsec11t3" class="pad1">Amazon Mechanical Turk accounts</h4>
			
			<!--Your Own Account or Lab Account? Pros/Cons-->
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
			
			<hr>

			<h2 id="subsec12" class="pad1">Designing Online Studies</h2>

			<p>....</p>
			
			<p>....</p>
			
			<h4 id="subsec12t1" class="pad1">Running social science research on MTurk</h4>
			
			<!--Frame the question of ethics, consent process, paying, workers as contractors (but payment standards will change by country) - students need to write their IRB, so they should think about these things-->
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>

			<p>....</p>
			
			<p>....</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
			
			<h4 id="subsec12t2" class="pad1">A typical social science project on MTurk</h4>
			
			<!--Create a sample project on MTurk, walk-through with students what this looks like to show the different elements of the MTurk projects, what students will need to input 
			●	How to set up your MTurk Hit Page (https://blog.mturk.com/tasks-can-now-scale-to-a-workers-browser-window-size-c6e66f4bdfc9 )-->
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>What is listed here is not the only type of study to find on MTurk. For example, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6415984/" class="copy-link">Qureshi et al. (2019)</a> showed MTurk workers the results of medical tests to examine how well people (patients) understand what they're seeing in terms of diagnoses.</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
			
			<h4 id="subsec12t3" class="pad1">Special qualifications and properties on MTurk</h4>
			
			<!--Qualifications & Excluding MTurk workers, payments on MTurk
This is a specific part of the  MTurk  GUI - also, mention that -->

			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
			
			<hr>
			
			<h2 id="subsec13" class="pad1">Additional Considerations</h2>
			
			<p>....</p>
			
			<p>....</p>
			
			<h4 id="subsec13t1" class="pad1">Diversity and Inclusion</h4>
			
			<!--Discuss WEIRD populations on MTurk and how MTurk does not fully solves this within social science
Also discuss subject selection within MTurk with the Master workers/# hits done/approval rate %/etc.
atlantic ethics article - https://www.nytimes.com/interactive/2019/11/15/nyregion/amazon-mechanical-turk.html vs. https://www.behind-the-enemy-lines.com/2019/11/mechanical-turk-97-cents-per-hour-and.html-->
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>

			<p>....</p>
			
			<p>....</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
			
			<h4 id="subsec13t2" class="pad1">Tips for running MTurk participants</h4>
			
			<!--Podcast-like interviews across disciplines, get grad students to describe research within 1-2 minutes, then describe issues with running experiments online
Always replicate regardless of the discipline

Tips from a communication researcher:
●	Experience MTurk as a worker first; complete a few easy academic HITs to get a feel for the site.
●	Know and understand the rules about what types of HITs are acceptable to post on MTurk, and adhere to privacy regulations.
●	Design your study to ensure qualified respondents, either by requesting and paying for specific characteristics in respondents, or by implementing a short screening survey.
●	Use attention checks to ensure that respondents are real people (and not robots) and to make sure they are adhering to your survey guidelines and paying attention to the questions.
●	Optimize surveys to slow down respondents and collect more satisfactory and comprehensive responses to open-ended questions.
●	Pretest all surveys yourself to check functionality and estimated completion times, and adjust as necessary.
●	Engage with workers who contact you to answer questions they may have about the task, or to fix an issue they may have encountered with the survey – this will build trust between you and the workers. ← this is the only recommendation I’d edit a bit.

Add in comments on being a good requester too.-->

			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>
			
			<h4 id="subsec13t3" class="pad1">Frequently Asked Questions</h4>
			
			<p>What sorts of studies can be run on these crowdsourced platforms?</p>
			
			<p>A lot. For instance, if you need to run a longitudinal or multi-day study, .... Even on Prolific, another crowdsourced site (link to wishlist), researchers were able to find</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>

			<p>Don't forget to <a href="#testyourself" class="copy-link">test yourself</a> on the material presented here.</p>			
			
			<h4 id="subsec13t4" class="pad1">Applied Exercise: What did these experiments do wrong?</h4>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<p>....</p>
			
			<h4 id="subsec13t5" class="pad1">Unknown Frontiers</h4>
			
			<p>Perhaps one of the most unknown consequences of using crowdsourced samples is the effect of crowdsourcing on the experiment. At any time, a participant may catch your experiment ... (but psych pool is similar to MTurk anyway?) </p>
			
			<p>For example, a lot of older psychology research ... Now, many folks have put forward studies showing that effects are similar between MTurk and psychology pool participants (example), but that ... When crowdsourcing, however, ... One study examined whether repeated exposure to the Cognitive Reflection Test </p>
			
			<!--Most investigators have concluded that both in terms of attention and quality, data collected on MTurk was not inferior to data collected from student and other convenience samples (Crump et al., 2013; Landers and Behrend, 2015; Hauser and Schwarz, 2016; McCredie and Morey, 2018; Coppock, 2019; Semmelmann & Weigelt, 2017; Zwaan et al., 2018)). Samples from established professional online panels have been found to be more representative of the general population than MTurk samples, but not to be necessarily of higher quality (Kees et al., 2017). <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6753310/" class="copy-link">Kochari et al., 2019</a>
			
			A number of studies have successfully replicated classical effects in cognitive psychology in web-based studies: Stroop, Flanker, Simon, visual search, attentional blink, serial position, masked priming, associative priming, repetition priming, lexical decision task etc. (Barnhoorn, Haasnoot, Bocanegra, & van Steenbergen, 2015; Crump et al., 2013; Hilbig, 2016; Semmelmann & Weigelt, 2017; Zwaan et al., 2018
			
			RT specific: reasonable timing control (de Leeuw & Motz, 2016; Hilbig, 2016; Semmelmann & Weigelt, 2017).
			
			Critics argued that these “professional participants” might differ from traditional participants in criticial aspects (Dennis, 2001; Hillygus et al., 2014; Matthijsse et al., 2015). At first, the reported size of the MTurk population seemed to address this problem sufficiently, but two developments contributed to its reemergence: Stewart et al. (2015) found that the population of participants available to any given lab was far below the reported number and closer to around 7,000 participants, similar to the size of university pools.-->
			
			<p>Outstanding questions:</p>
			
			<p>1. To what extent does nonnaivete impact your effect of interest? Do you know this for your particular field and effect?</p> 
			
			<p>This seems to depend somewhat on your particular field. For example, one of the effects that I study, the Stroop effect, occurs when people automatically read ... (named after J.R. Stroop). The effect is subject to a number of factors (e.g., familiarity with the language being used to create conflict between reading and following instructions), but the effect is also so large that most participants show a Stroop effect. On the other hand, crowdsourcing can </p>
			
			"One general issue with using online recruitment services is that participants are likely to complete many studies over time and, therefore, there is a high likelihood that they have experience with similar experimental paradigms or with completing artificial tasks in general. In other words, some of these participants might not be considered naive to the task (Chandler et al., 2014; Peer et al., 2017; Stewart et al., 2015). Participant naivety to the experimental manipulation is often desirable as it is an important assumption of some paradigms (see Chandler, Paolacci, Peer, Mueller, & Ratliff, 2015; Weber & Cook, 1972, for reviews of cases where participant non-naivety can lead to different effect sizes)."
			
			<p>2. How has the COVID-19 pandemic impacted recruitment?</p>
			
			<p>Word of mouth has suggested worse data quality or the same as usual -- which is not all that different from pre-COVID-19 -- and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7211671/" class="copy-link">Lourenco and Tasimi (2020)</a> speculate in a commentary that the COVID-19 pandemic may make samples less diverse and generalizable, given the potential paucity of internet access. In terms of quantitative research, a couples of papers have attempted to address this question. For example, <a href="https://psyarxiv.com/vktqu" class="copy-link">Arechar and Rand (2020)</a> analyze the over ten thousand responses from 16 studies run on MTurk between February 25, 2020 and May 14,2020 relative to previous lab studies and find that "participants are more likely to be Republicans (traditionally  under-represented  on MTurk) and less reflective (as measured by the Cognitive Reflection Test), and somewhat less likely to be white and experienced with MTurk. Most of these differences are explained by an influx of new participants into the  MTurk subject pool who are more diverse and representative - but also less attentive – than previous MTurkers." Meanwhile, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7266762/" class="copy-link">Moss, Rosenzweig, Robinson, and Litman (2020)</a> examined small samples of participants from CloudResearch run through all the months of 2019 and from January-May 2020 and found similar demographics across the participant samples in terms of income, gender, and race. Note, of course, that these folks are all affiliated with "Prime Research Solutions", which is an extension of the MTurk platform (the company that owns CloudResearch). Personally, I can say that I've had a lot more folks who do not even try in my experiment (i.e., higher exclusion rates), but that could also result from my particular approach to MTurk.</p>
			
			<p>3. To what extent does what I wrote above about MTurk participants apply to all crowdsourced participants?</p>
			
			<p>Are they the same psychologically? Is this a characteristic of participating in crowdsourced pools, or is it specific to Amazon Mechanical Turk? I do not currently know of studies that compare across crowdsourcing platforms in terms of population based characteristics - for one, they would need to recruit across different regions for compairson, and I believe that currently, most platforms have a "strongest" area (like MTurk with the US, Prolific with Europe; see <a href="wishlist.html" class="copy-link">Wishlist</a> page). Gordon Pennycook has made a few comments about how MTurk and Lucid compare for politics-related studies (Twitter thread), but beyond informal commentary, we'll have to look to this for the future.</p>
			
			<h2 id="testyourself" class="pad1">Test Yourself:</h2>
			
			<div class="quiz-container mainfont">
			  <div id="quiz"></div>
			</div>
			<button id="previous mainfont bttn">Previous Question</button>
			<button id="next mainfont bttn">Next Question</button>
			<button id="submit mainfont bttn">Submit Quiz</button>
			<div id="results mainfont"></div>
			
			<h2 id="assignments" class="pad1">Assignments:</h2>
			
			<ul class="fa-ul">
				<li><i class="fa-li fas fa-user"></i>Knowing the ethics of using crowdsourcing, now write a sample IRB (Institutional Review Board) or set of internal guidelines on *how* you plan to use the site. For example, determine an ethical amount of pay; how long you expect your study (or studies) to take; what you'll have participants do; what your interface with participants will look like; who you plan to recruit, etc.</li>
				<li><i class="fa-li fas fa-user-clock"></i>Knowing what you do about crowdsourcing, determine what you need for your online study: what are the conditions? What will you ask participants to do? What sorts of things will you need the code or survey to do? What are the qualifications or characteristics you want your participants to have? Then write out instructions and identify areas where MTurk workers could get confused in your study.</li>
				<li><i class="fa-li fas fa-users"></i>Create a preregistered plan for your project that includes the above, incorporating things like the qualifications you've imposed, properties of the HIT preview, the duration of your HIT, payment amount, time of day and date for your batches, etc. One way we can determine the extent to which studies from crowdsourced populations generalize is by reporting all the details of a study and meta-analyzing their impact.</li>
				<!--<li><i class="fa-li fas fa-users-cog"></i></li>-->
			</ul>

			<div class="scrollstyle mainfont pad1" id="top-scroll" aria-labelledby="scroll-to-top">
				<a class="copy-link" href="#top" rel="tooltip" data-toggle="tooltip" aria-labelledby="tooltip" data-placement="left" title="Scroll to top">
					<i class="fas fa-angle-up fa-3x"></i>
				</a>
			</div>
			<div class="row pad-l1 pad-b75 pad-t75"></div>
		</div>
	</div>	
    <!-- Bootstrap core JavaScript-->
    <!-- Placed at the end of the document so the pages load faster -->	
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>
	
	<script type="text/javascript">
	$(document).ready(function(){
	
		//this is the scroll to the top arrow; it selects any select that says href=#top and when you click that link, it animates the html body to slowly scroll to the top
		$("a[href='#top']").click(function() {
            $('html,body').animate({scrollTop: 0}, "slow");
			return false;
        });
		//this is the tooltip hover that explains what the scroll to the top arrow is in case someone is not familiar with that
		$('[rel=tooltip]').tooltip({ trigger: "hover" });
		
		function buildQuiz(){
		  // variable to store the HTML output
		  const output = [];

		  // for each question...
		  myQuestions.forEach(
			(currentQuestion, questionNumber) => {

			  // variable to store the list of possible answers
			  const answers = [];

			  // and for each available answer...
			  for(letter in currentQuestion.answers){

				// ...add an HTML radio button
				answers.push(
				  `<label>
					<input type="radio" name="question${questionNumber}" value="${letter}">
					${letter} :
					${currentQuestion.answers[letter]}
				  </label>`
				);
			  }

			  // add this question and its answers to the output
			  output.push(
				  `<div class="slide">
					<div class="question"> ${currentQuestion.question} </div>
					<div class="answers"> ${answers.join("")} </div>
				  </div>`
				);
			}
		  );

		  // finally combine our output list into one string of HTML and put it on the page
		  quizContainer.innerHTML = output.join('');
		}

		function showResults(){

		  // gather answer containers from our quiz
		  const answerContainers = quizContainer.querySelectorAll('.answers');

		  // keep track of user's answers
		  let numCorrect = 0;

		  // for each question...
		  myQuestions.forEach( (currentQuestion, questionNumber) => {

			// find selected answer
			const answerContainer = answerContainers[questionNumber];
			const selector = `input[name=question${questionNumber}]:checked`;
			const userAnswer = (answerContainer.querySelector(selector) || {}).value;

			// if answer is correct
			if(userAnswer === currentQuestion.correctAnswer){
			  // add to the number of correct answers
			  numCorrect++;

			  // color the answers green
			  answerContainers[questionNumber].style.color = 'lightgreen';
			}
			// if answer is wrong or blank
			else{
			  // color the answers red
			  answerContainers[questionNumber].style.color = 'red';
			}
		  });

		  // show number of correct answers out of total
		  resultsContainer.innerHTML = `${numCorrect} out of ${myQuestions.length}`;
		}
		
		function showSlide(n) {
		  slides[currentSlide].classList.remove('active-slide');
		  slides[n].classList.add('active-slide');
		  currentSlide = n;
		  if(currentSlide === 0){
			previousButton.style.display = 'none';
		  }
		  else{
			previousButton.style.display = 'inline-block';
		  }
		  if(currentSlide === slides.length-1){
			nextButton.style.display = 'none';
			submitButton.style.display = 'inline-block';
		  }
		  else{
			nextButton.style.display = 'inline-block';
			submitButton.style.display = 'none';
		  }
		}
		
		function showNextSlide() {
		  showSlide(currentSlide + 1);
		}

		function showPreviousSlide() {
		  showSlide(currentSlide - 1);
		}
				
		//from: https://www.sitepoint.com/simple-javascript-quiz/
		const quizContainer = document.getElementById('quiz');
		const resultsContainer = document.getElementById('results');
		const submitButton = document.getElementById('submit');
		const myQuestions = [
		  {
			question: "How does crowdsourcing impact participant behavior?",
			answers: {
			  a: "Douglas Crockford",
			  b: "Sheryl Sandberg",
			  c: "Brendan Eich",
			  d: " "
			},
			correctAnswer: "c"
		  },
		  {
			question: "Which one of these is a JavaScript package manager?",
			answers: {
			  a: "Node.js",
			  b: "TypeScript",
			  c: "Brendan Eich",
			  d: " "
			},
			correctAnswer: "c"
		  },
		  {
			question: "Which tool can you use to ensure code quality?",
			answers: {
			  a: "Angular",
			  b: "jQuery",
			  c: "RequireJS",
			  d: "ESLint"
			},
			correctAnswer: "d"
		  }
		];

		// display quiz right away
		buildQuiz();
		
		// Pagination
		const previousButton = document.getElementById("previous");
		const nextButton = document.getElementById("next");
		const slides = document.querySelectorAll(".slide");
		let currentSlide = 0;
		
		// Show the first slide
		showSlide(currentSlide);

		previousButton.addEventListener("click", showPreviousSlide);
		nextButton.addEventListener("click", showNextSlide);
		
	});
	</script>
</body>
</html>